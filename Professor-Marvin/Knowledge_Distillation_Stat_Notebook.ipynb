{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mociRm5H2XbT"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uaHcFpo6l6l",
        "outputId": "2e931432-0251-4699-e67d-a0001e423c70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -V"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gaiao1J-kfCR",
        "outputId": "b4434655-ecd4-4c85-e6f4-d21c7505d083"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.8.15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys  \n",
        "sys.path.insert(0, '/content/drive/MyDrive/TinyML/TinyML Project/kws_test/Spoken-Keyword-Spotting')"
      ],
      "metadata": {
        "id": "oOouzqkD-2Pa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#arman\n",
        "%cd /content/drive/MyDrive/TinyML/TinyML Project/kws_test/Spoken-Keyword-Spotting/src"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "do8B04HF6pOK",
        "outputId": "ef91d2f1-d849-4363-ae2c-1a7376f927b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/TinyML/TinyML Project/kws_test/Spoken-Keyword-Spotting/src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubuc3Tog2XbU"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install --upgrade pip\n",
        "# !apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg\n",
        "\n",
        "# !pip install pyaudio\n",
        "# %cd /content/drive/MyDrive/Spoken-Keyword-Spotting\n",
        "# !pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "mMzbvxi2BO1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vsxHHHHVBXUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umdFKAQ_2XbW"
      },
      "source": [
        "## Construct `Distiller()` class\n",
        "\n",
        "The custom `Distiller()` class, overrides the `Model` methods `train_step`, `test_step`,\n",
        "and `compile()`. In order to use the distiller, we need:\n",
        "\n",
        "- A trained teacher model\n",
        "- A student model to train\n",
        "- A student loss function on the difference between student predictions and ground-truth\n",
        "- A distillation loss function, along with a `temperature`, on the difference between the\n",
        "soft student predictions and the soft teacher labels\n",
        "- An `alpha` factor to weight the student and distillation loss\n",
        "- An optimizer for the student and (optional) metrics to evaluate performance\n",
        "\n",
        "In the `train_step` method, we perform a forward pass of both the teacher and student,\n",
        "calculate the loss with weighting of the `student_loss` and `distillation_loss` by `alpha` and\n",
        "`1 - alpha`, respectively, and perform the backward pass. Note: only the student weights are updated,\n",
        "and therefore we only calculate the gradients for the student weights.\n",
        "\n",
        "In the `test_step` method, we evaluate the student model on the provided dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPkp0boV2XbX"
      },
      "outputs": [],
      "source": [
        "class Distiller(keras.Model):\n",
        "    def __init__(self, student, teacher):\n",
        "        super(Distiller, self).__init__()\n",
        "        self.teacher = teacher\n",
        "        self.student = student\n",
        "\n",
        "    def compile(\n",
        "        self,\n",
        "        optimizer,\n",
        "        metrics,\n",
        "        student_loss_fn,\n",
        "        distillation_loss_fn,\n",
        "        alpha=0.1,\n",
        "        temperature=3,\n",
        "        run_eagerly=False\n",
        "    ):\n",
        "        \"\"\" Configure the distiller.\n",
        "\n",
        "        Args:\n",
        "            optimizer: Keras optimizer for the student weights\n",
        "            metrics: Keras metrics for evaluation\n",
        "            student_loss_fn: Loss function of difference between student\n",
        "                predictions and ground-truth\n",
        "            distillation_loss_fn: Loss function of difference between soft\n",
        "                student predictions and soft teacher predictions\n",
        "            alpha: weight to student_loss_fn and 1-alpha to distillation_loss_fn\n",
        "            temperature: Temperature for softening probability distributions.\n",
        "                Larger temperature gives softer distributions.\n",
        "        \"\"\"\n",
        "        super(Distiller, self).compile(optimizer=optimizer, metrics=metrics, run_eagerly=run_eagerly)\n",
        "        self.student_loss_fn = student_loss_fn\n",
        "        self.distillation_loss_fn = distillation_loss_fn\n",
        "        self.alpha = alpha\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def train_step(self, data):\n",
        "        print('train step entered')\n",
        "        # Unpack data\n",
        "        x, y = data\n",
        "        print(x)\n",
        "        print(y)\n",
        "        # Forward pass of teacher\n",
        "        teacher_predictions = self.teacher(x, training=False)\n",
        "        print('forward pass of teacher done')\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Forward pass of student\n",
        "            student_predictions = self.student(x, training=True)\n",
        "            print('forward pass of student done')\n",
        "\n",
        "            # Compute losses\n",
        "            student_loss = self.student_loss_fn(y, student_predictions)\n",
        "\n",
        "            # Compute scaled distillation loss from https://arxiv.org/abs/1503.02531\n",
        "            # The magnitudes of the gradients produced by the soft targets scale\n",
        "            # as 1/T^2, multiply them by T^2 when using both hard and soft targets.\n",
        "            distillation_loss = (\n",
        "                self.distillation_loss_fn(\n",
        "                    tf.nn.softmax(teacher_predictions / self.temperature, axis=1),\n",
        "                    tf.nn.softmax(student_predictions / self.temperature, axis=1),\n",
        "                )\n",
        "                * self.temperature**2\n",
        "            )\n",
        "\n",
        "            loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n",
        "\n",
        "        print('losses have been computed')\n",
        "        # Compute gradients\n",
        "        trainable_vars = self.student.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "        print('gradients completed')\n",
        "\n",
        "        # Update weights\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "        print('optimizer done')\n",
        "\n",
        "        # Update the metrics configured in `compile()`.\n",
        "        self.compiled_metrics.update_state(y, student_predictions)\n",
        "\n",
        "        # Return a dict of performance\n",
        "        results = {m.name: m.result() for m in self.metrics}\n",
        "        results.update(\n",
        "            {\"student_loss\": student_loss, \"distillation_loss\": distillation_loss}\n",
        "        )\n",
        "        print('train step function done: ', results)\n",
        "        return results\n",
        "\n",
        "    def test_step(self, data):\n",
        "        # Unpack the data\n",
        "        x, y = data\n",
        "\n",
        "        # Compute predictions\n",
        "        y_prediction = self.student(x, training=False)\n",
        "\n",
        "        # Calculate the loss\n",
        "        student_loss = self.student_loss_fn(y, y_prediction)\n",
        "\n",
        "        # Update the metrics.\n",
        "        self.compiled_metrics.update_state(y, y_prediction)\n",
        "\n",
        "        # Return a dict of performance\n",
        "        results = {m.name: m.result() for m in self.metrics}\n",
        "        results.update({\"student_loss\": student_loss})\n",
        "        return results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyZyA8RO2XbZ"
      },
      "source": [
        "## Create student and teacher models\n",
        "\n",
        "Initialy, we create a teacher model and a smaller student model. Both models are\n",
        "convolutional neural networks and created using `Sequential()`,\n",
        "but could be any Keras model."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from src.models import create_model\n",
        "from keras.models import load_model\n",
        "teacher = load_model(\"../models/marvin_kws-3epoch.h5\") #julian model: models/marvin_kws_Dec1_5pm.h5\n",
        "teacher.summary()\n",
        "student = create_model([2, 4, 8, 16, 32])\n",
        "student_scratch = keras.models.clone_model(student)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygNL0P534Obx",
        "outputId": "78fca00f-d03b-4675-9315-df3de9e3309d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape (Reshape)           (None, 99, 40, 1)         0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 99, 40, 1)        4         \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 99, 40, 16)        160       \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 99, 40, 16)       64        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " re_lu (ReLU)                (None, 99, 40, 16)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 49, 20, 16)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 49, 20, 16)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 49, 20, 32)        4640      \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 49, 20, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " re_lu_1 (ReLU)              (None, 49, 20, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 24, 10, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 24, 10, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 24, 10, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 24, 10, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " re_lu_2 (ReLU)              (None, 24, 10, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 12, 5, 64)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 12, 5, 64)         0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 12, 5, 128)        73856     \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 12, 5, 128)       512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " re_lu_3 (ReLU)              (None, 12, 5, 128)        0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 6, 2, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 6, 2, 128)         0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 6, 2, 256)         295168    \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 6, 2, 256)        1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " re_lu_4 (ReLU)              (None, 6, 2, 256)         0         \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 3, 1, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 3, 1, 256)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 768)               0         \n",
            "                                                                 \n",
            " features512 (Dense)         (None, 512)               393728    \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " re_lu_5 (ReLU)              (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " features256 (Dense)         (None, 256)               131328    \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " re_lu_6 (ReLU)              (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 31)                7967      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 930,403\n",
            "Trainable params: 927,873\n",
            "Non-trainable params: 2,530\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape_1 (Reshape)         (None, 99, 40, 1)         0         \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 99, 40, 1)        4         \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 99, 40, 2)         20        \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 99, 40, 2)        8         \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " re_lu_7 (ReLU)              (None, 99, 40, 2)         0         \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 49, 20, 2)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 49, 20, 2)         0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 49, 20, 4)         76        \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 49, 20, 4)        16        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_8 (ReLU)              (None, 49, 20, 4)         0         \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 24, 10, 4)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 24, 10, 4)         0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 24, 10, 8)         296       \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 24, 10, 8)        32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_9 (ReLU)              (None, 24, 10, 8)         0         \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 12, 5, 8)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 12, 5, 8)          0         \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 12, 5, 16)         1168      \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 12, 5, 16)        64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_10 (ReLU)             (None, 12, 5, 16)         0         \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 6, 2, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 6, 2, 16)          0         \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 6, 2, 32)          4640      \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 6, 2, 32)         128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_11 (ReLU)             (None, 6, 2, 32)          0         \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 3, 1, 32)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 3, 1, 32)          0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 96)                0         \n",
            "                                                                 \n",
            " features512 (Dense)         (None, 512)               49664     \n",
            "                                                                 \n",
            " batch_normalization_14 (Bat  (None, 512)              2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_12 (ReLU)             (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " features256 (Dense)         (None, 256)               131328    \n",
            "                                                                 \n",
            " batch_normalization_15 (Bat  (None, 256)              1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_13 (ReLU)             (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 31)                7967      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 198,483\n",
            "Trainable params: 196,821\n",
            "Non-trainable params: 1,662\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit_optimize python_speech_features path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPgk9ETXSYoA",
        "outputId": "4bb53ac2-2c7d-48ce-f215-901b14cbab18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit_optimize in /usr/local/lib/python3.8/dist-packages (0.9.0)\n",
            "Requirement already satisfied: python_speech_features in /usr/local/lib/python3.8/dist-packages (0.6)\n",
            "Requirement already satisfied: path in /usr/local/lib/python3.8/dist-packages (16.6.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.8/dist-packages (from scikit_optimize) (1.21.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit_optimize) (1.2.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.8/dist-packages (from scikit_optimize) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.8/dist-packages (from scikit_optimize) (1.0.2)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.8/dist-packages (from scikit_optimize) (21.10.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from pyaml>=16.9->scikit_optimize) (6.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20.0->scikit_optimize) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create a file that just returns a tf.data.dataset of our data\n",
        "from create_tf_dataset import create_train_and_val\n",
        "\n",
        "train_data, train_steps, val_data, val_steps = create_train_and_val()\n",
        "\n",
        "# train_data = train_data.as_numpy_iterator()\n",
        "# val_data = val_data.as_numpy_iterator()\n",
        "# print(type(train_data), type(val_data))\n",
        "# for x,y in train_data:\n",
        "#   print(x)\n",
        "#   break"
      ],
      "metadata": {
        "id": "qO9tROyh4ZQ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0e3a46f-3da1-4944-953f-45697c325ea0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train data setup complete.\n",
            "test data setup complete.\n",
            "Input data setup successful.\n",
            "Dataset statistics\n",
            "Train files: 51142\n",
            "Validation files: 6798\n",
            "Dev test files: 6835\n",
            "Test files: 2567\n",
            "pandas started to shuffle\n",
            "pandas shuffling over\n",
            "i:  0\n",
            "i:  100\n",
            "i:  200\n",
            "i:  300\n",
            "i:  400\n",
            "i:  500\n",
            "i:  600\n",
            "i:  700\n",
            "i:  800\n",
            "i:  900\n",
            "i:  1000\n",
            "i:  1100\n",
            "i:  1200\n",
            "i:  1300\n",
            "i:  1400\n",
            "i:  1500\n",
            "i:  1600\n",
            "i:  1700\n",
            "i:  1800\n",
            "i:  1900\n",
            "i:  2000\n",
            "i:  2100\n",
            "i:  2200\n",
            "i:  2300\n",
            "i:  2400\n",
            "i:  2500\n",
            "pandas started to shuffle val\n",
            "pandas shuffling over\n",
            "i:  0\n",
            "i:  10\n",
            "i:  20\n",
            "i:  30\n",
            "i:  40\n",
            "i:  50\n",
            "i:  60\n",
            "i:  70\n",
            "i:  80\n",
            "i:  90\n",
            "i:  100\n",
            "i:  110\n",
            "i:  120\n",
            "i:  130\n",
            "i:  140\n",
            "i:  150\n",
            "i:  160\n",
            "i:  170\n",
            "i:  180\n",
            "i:  190\n",
            "i:  200\n",
            "i:  210\n",
            "i:  220\n",
            "i:  230\n",
            "i:  240\n",
            "i:  250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for elt in train_data:\n",
        "#   print(elt)\n",
        "#   break"
      ],
      "metadata": {
        "id": "pLhNHb8v3nwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRqrnWTS2Xbe"
      },
      "source": [
        "## Distill teacher to student\n",
        "\n",
        "We have already trained the teacher model, and we only need to initialize a\n",
        "`Distiller(student, teacher)` instance, `compile()` it with the desired losses,\n",
        "hyperparameters and optimizer, and distill the teacher to the student."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gr-Sz5YV2Xbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10ae7a80-2fac-4783-823c-19a6a95d2ae1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train steps:  20\n",
            "Epoch 1/180\n",
            "train step entered\n",
            "Tensor(\"IteratorGetNext:0\", shape=(None, 99, 40), dtype=float32)\n",
            "Tensor(\"IteratorGetNext:1\", shape=(None,), dtype=int32)\n",
            "forward pass of teacher done\n",
            "forward pass of student done\n",
            "losses have been computed\n",
            "gradients completed\n",
            "optimizer done\n",
            "train step function done:  {'sparse_categorical_accuracy': <tf.Tensor 'Identity:0' shape=() dtype=float32>, 'student_loss': <tf.Tensor 'sparse_categorical_crossentropy/weighted_loss/value:0' shape=() dtype=float32>, 'distillation_loss': <tf.Tensor 'mul:0' shape=() dtype=float32>}\n",
            "train step entered\n",
            "Tensor(\"IteratorGetNext:0\", shape=(None, 99, 40), dtype=float32)\n",
            "Tensor(\"IteratorGetNext:1\", shape=(None,), dtype=int32)\n",
            "forward pass of teacher done\n",
            "forward pass of student done\n",
            "losses have been computed\n",
            "gradients completed\n",
            "optimizer done\n",
            "train step function done:  {'sparse_categorical_accuracy': <tf.Tensor 'Identity:0' shape=() dtype=float32>, 'student_loss': <tf.Tensor 'sparse_categorical_crossentropy/weighted_loss/value:0' shape=() dtype=float32>, 'distillation_loss': <tf.Tensor 'mul:0' shape=() dtype=float32>}\n",
            "20/20 [==============================] - 3s 55ms/step - sparse_categorical_accuracy: 0.6695 - student_loss: 1.0189 - distillation_loss: 0.0077 - val_sparse_categorical_accuracy: 0.4727 - val_student_loss: 1.7660\n",
            "Epoch 2/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6679 - student_loss: 1.0181 - distillation_loss: 0.0076 - val_sparse_categorical_accuracy: 0.4883 - val_student_loss: 1.7351\n",
            "Epoch 3/180\n",
            "20/20 [==============================] - 1s 40ms/step - sparse_categorical_accuracy: 0.6753 - student_loss: 1.0113 - distillation_loss: 0.0077 - val_sparse_categorical_accuracy: 0.5039 - val_student_loss: 1.7437\n",
            "Epoch 4/180\n",
            "20/20 [==============================] - 1s 40ms/step - sparse_categorical_accuracy: 0.6690 - student_loss: 1.0206 - distillation_loss: 0.0077 - val_sparse_categorical_accuracy: 0.4961 - val_student_loss: 1.7223\n",
            "Epoch 5/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6711 - student_loss: 1.0195 - distillation_loss: 0.0077 - val_sparse_categorical_accuracy: 0.5117 - val_student_loss: 1.6730\n",
            "Epoch 6/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6743 - student_loss: 1.0209 - distillation_loss: 0.0077 - val_sparse_categorical_accuracy: 0.5078 - val_student_loss: 1.7001\n",
            "Epoch 7/180\n",
            "20/20 [==============================] - 1s 40ms/step - sparse_categorical_accuracy: 0.6702 - student_loss: 1.0215 - distillation_loss: 0.0077 - val_sparse_categorical_accuracy: 0.5039 - val_student_loss: 1.7111\n",
            "Epoch 8/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6764 - student_loss: 1.0059 - distillation_loss: 0.0078 - val_sparse_categorical_accuracy: 0.5312 - val_student_loss: 1.6602\n",
            "Epoch 9/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6732 - student_loss: 1.0070 - distillation_loss: 0.0078 - val_sparse_categorical_accuracy: 0.5273 - val_student_loss: 1.6686\n",
            "Epoch 10/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6737 - student_loss: 1.0020 - distillation_loss: 0.0077 - val_sparse_categorical_accuracy: 0.5156 - val_student_loss: 1.6479\n",
            "Epoch 11/180\n",
            "20/20 [==============================] - 1s 40ms/step - sparse_categorical_accuracy: 0.6758 - student_loss: 0.9971 - distillation_loss: 0.0078 - val_sparse_categorical_accuracy: 0.4883 - val_student_loss: 1.7464\n",
            "Epoch 12/180\n",
            "20/20 [==============================] - 1s 40ms/step - sparse_categorical_accuracy: 0.6818 - student_loss: 0.9945 - distillation_loss: 0.0078 - val_sparse_categorical_accuracy: 0.4883 - val_student_loss: 1.7729\n",
            "Epoch 13/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6802 - student_loss: 0.9772 - distillation_loss: 0.0078 - val_sparse_categorical_accuracy: 0.4688 - val_student_loss: 1.7397\n",
            "Epoch 14/180\n",
            "20/20 [==============================] - 1s 40ms/step - sparse_categorical_accuracy: 0.6710 - student_loss: 0.9928 - distillation_loss: 0.0077 - val_sparse_categorical_accuracy: 0.5039 - val_student_loss: 1.7040\n",
            "Epoch 15/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6732 - student_loss: 1.0069 - distillation_loss: 0.0079 - val_sparse_categorical_accuracy: 0.5039 - val_student_loss: 1.6882\n",
            "Epoch 16/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6759 - student_loss: 0.9790 - distillation_loss: 0.0078 - val_sparse_categorical_accuracy: 0.4766 - val_student_loss: 1.7031\n",
            "Epoch 17/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6782 - student_loss: 0.9991 - distillation_loss: 0.0078 - val_sparse_categorical_accuracy: 0.4961 - val_student_loss: 1.6757\n",
            "Epoch 18/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6763 - student_loss: 1.0032 - distillation_loss: 0.0078 - val_sparse_categorical_accuracy: 0.5117 - val_student_loss: 1.6877\n",
            "Epoch 19/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6713 - student_loss: 1.0024 - distillation_loss: 0.0078 - val_sparse_categorical_accuracy: 0.4648 - val_student_loss: 1.7560\n",
            "Epoch 20/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6795 - student_loss: 0.9925 - distillation_loss: 0.0077 - val_sparse_categorical_accuracy: 0.4727 - val_student_loss: 1.7828\n",
            "Epoch 21/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6819 - student_loss: 0.9753 - distillation_loss: 0.0078 - val_sparse_categorical_accuracy: 0.5078 - val_student_loss: 1.6967\n",
            "Epoch 22/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6771 - student_loss: 0.9919 - distillation_loss: 0.0079 - val_sparse_categorical_accuracy: 0.5117 - val_student_loss: 1.6906\n",
            "Epoch 23/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6812 - student_loss: 0.9713 - distillation_loss: 0.0078 - val_sparse_categorical_accuracy: 0.4883 - val_student_loss: 1.7136\n",
            "Epoch 24/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.6863 - student_loss: 0.9730 - distillation_loss: 0.0078 - val_sparse_categorical_accuracy: 0.4844 - val_student_loss: 1.7067\n",
            "Epoch 25/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6795 - student_loss: 0.9817 - distillation_loss: 0.0078 - val_sparse_categorical_accuracy: 0.4727 - val_student_loss: 1.7383\n",
            "Epoch 26/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6805 - student_loss: 0.9802 - distillation_loss: 0.0078 - val_sparse_categorical_accuracy: 0.4805 - val_student_loss: 1.7827\n",
            "Epoch 27/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6829 - student_loss: 0.9777 - distillation_loss: 0.0079 - val_sparse_categorical_accuracy: 0.4883 - val_student_loss: 1.7400\n",
            "Epoch 28/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6832 - student_loss: 0.9849 - distillation_loss: 0.0078 - val_sparse_categorical_accuracy: 0.4922 - val_student_loss: 1.7487\n",
            "Epoch 29/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6850 - student_loss: 0.9656 - distillation_loss: 0.0079 - val_sparse_categorical_accuracy: 0.4805 - val_student_loss: 1.7783\n",
            "Epoch 30/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6891 - student_loss: 0.9665 - distillation_loss: 0.0077 - val_sparse_categorical_accuracy: 0.4922 - val_student_loss: 1.7057\n",
            "Epoch 31/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6847 - student_loss: 0.9720 - distillation_loss: 0.0079 - val_sparse_categorical_accuracy: 0.4805 - val_student_loss: 1.7072\n",
            "Epoch 32/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.6812 - student_loss: 0.9799 - distillation_loss: 0.0079 - val_sparse_categorical_accuracy: 0.4844 - val_student_loss: 1.7343\n",
            "Epoch 33/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6904 - student_loss: 0.9595 - distillation_loss: 0.0079 - val_sparse_categorical_accuracy: 0.5117 - val_student_loss: 1.7144\n",
            "Epoch 34/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6881 - student_loss: 0.9681 - distillation_loss: 0.0079 - val_sparse_categorical_accuracy: 0.4922 - val_student_loss: 1.6729\n",
            "Epoch 35/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6902 - student_loss: 0.9504 - distillation_loss: 0.0079 - val_sparse_categorical_accuracy: 0.4922 - val_student_loss: 1.7051\n",
            "Epoch 36/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6825 - student_loss: 0.9720 - distillation_loss: 0.0079 - val_sparse_categorical_accuracy: 0.4922 - val_student_loss: 1.7465\n",
            "Epoch 37/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.6835 - student_loss: 0.9678 - distillation_loss: 0.0078 - val_sparse_categorical_accuracy: 0.4805 - val_student_loss: 1.7549\n",
            "Epoch 38/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6890 - student_loss: 0.9548 - distillation_loss: 0.0079 - val_sparse_categorical_accuracy: 0.4805 - val_student_loss: 1.7991\n",
            "Epoch 39/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6967 - student_loss: 0.9498 - distillation_loss: 0.0079 - val_sparse_categorical_accuracy: 0.4844 - val_student_loss: 1.7992\n",
            "Epoch 40/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6847 - student_loss: 0.9628 - distillation_loss: 0.0079 - val_sparse_categorical_accuracy: 0.4805 - val_student_loss: 1.7290\n",
            "Epoch 41/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6896 - student_loss: 0.9585 - distillation_loss: 0.0079 - val_sparse_categorical_accuracy: 0.4531 - val_student_loss: 1.8586\n",
            "Epoch 42/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6891 - student_loss: 0.9567 - distillation_loss: 0.0078 - val_sparse_categorical_accuracy: 0.4805 - val_student_loss: 1.7517\n",
            "Epoch 43/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6963 - student_loss: 0.9388 - distillation_loss: 0.0079 - val_sparse_categorical_accuracy: 0.5117 - val_student_loss: 1.6781\n",
            "Epoch 44/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6910 - student_loss: 0.9561 - distillation_loss: 0.0080 - val_sparse_categorical_accuracy: 0.5078 - val_student_loss: 1.7184\n",
            "Epoch 45/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6915 - student_loss: 0.9611 - distillation_loss: 0.0079 - val_sparse_categorical_accuracy: 0.4727 - val_student_loss: 1.7975\n",
            "Epoch 46/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6979 - student_loss: 0.9450 - distillation_loss: 0.0080 - val_sparse_categorical_accuracy: 0.4727 - val_student_loss: 1.7467\n",
            "Epoch 47/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.6880 - student_loss: 0.9478 - distillation_loss: 0.0080 - val_sparse_categorical_accuracy: 0.4922 - val_student_loss: 1.7725\n",
            "Epoch 48/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6978 - student_loss: 0.9447 - distillation_loss: 0.0078 - val_sparse_categorical_accuracy: 0.4336 - val_student_loss: 1.8144\n",
            "Epoch 49/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6861 - student_loss: 0.9639 - distillation_loss: 0.0078 - val_sparse_categorical_accuracy: 0.4492 - val_student_loss: 1.8012\n",
            "Epoch 50/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6924 - student_loss: 0.9395 - distillation_loss: 0.0078 - val_sparse_categorical_accuracy: 0.4570 - val_student_loss: 1.8096\n",
            "Epoch 51/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6994 - student_loss: 0.9465 - distillation_loss: 0.0079 - val_sparse_categorical_accuracy: 0.4688 - val_student_loss: 1.8043\n",
            "Epoch 52/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6925 - student_loss: 0.9433 - distillation_loss: 0.0080 - val_sparse_categorical_accuracy: 0.4648 - val_student_loss: 1.7755\n",
            "Epoch 53/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6980 - student_loss: 0.9292 - distillation_loss: 0.0080 - val_sparse_categorical_accuracy: 0.4570 - val_student_loss: 1.8073\n",
            "Epoch 54/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.6970 - student_loss: 0.9337 - distillation_loss: 0.0079 - val_sparse_categorical_accuracy: 0.4570 - val_student_loss: 1.7595\n",
            "Epoch 55/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6965 - student_loss: 0.9375 - distillation_loss: 0.0080 - val_sparse_categorical_accuracy: 0.4414 - val_student_loss: 1.7218\n",
            "Epoch 56/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.6988 - student_loss: 0.9299 - distillation_loss: 0.0080 - val_sparse_categorical_accuracy: 0.4414 - val_student_loss: 1.7861\n",
            "Epoch 57/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7063 - student_loss: 0.9196 - distillation_loss: 0.0079 - val_sparse_categorical_accuracy: 0.4961 - val_student_loss: 1.7070\n",
            "Epoch 58/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6920 - student_loss: 0.9441 - distillation_loss: 0.0079 - val_sparse_categorical_accuracy: 0.4922 - val_student_loss: 1.6722\n",
            "Epoch 59/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.6888 - student_loss: 0.9470 - distillation_loss: 0.0079 - val_sparse_categorical_accuracy: 0.4727 - val_student_loss: 1.7502\n",
            "Epoch 60/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.6981 - student_loss: 0.9367 - distillation_loss: 0.0080 - val_sparse_categorical_accuracy: 0.4805 - val_student_loss: 1.7850\n",
            "Epoch 61/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6945 - student_loss: 0.9251 - distillation_loss: 0.0080 - val_sparse_categorical_accuracy: 0.4766 - val_student_loss: 1.7284\n",
            "Epoch 62/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.7008 - student_loss: 0.9344 - distillation_loss: 0.0080 - val_sparse_categorical_accuracy: 0.4766 - val_student_loss: 1.7526\n",
            "Epoch 63/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.7015 - student_loss: 0.9257 - distillation_loss: 0.0080 - val_sparse_categorical_accuracy: 0.4688 - val_student_loss: 1.7795\n",
            "Epoch 64/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6989 - student_loss: 0.9299 - distillation_loss: 0.0081 - val_sparse_categorical_accuracy: 0.4883 - val_student_loss: 1.7921\n",
            "Epoch 65/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6938 - student_loss: 0.9494 - distillation_loss: 0.0081 - val_sparse_categorical_accuracy: 0.4961 - val_student_loss: 1.7699\n",
            "Epoch 66/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6975 - student_loss: 0.9308 - distillation_loss: 0.0080 - val_sparse_categorical_accuracy: 0.4727 - val_student_loss: 1.8228\n",
            "Epoch 67/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.7026 - student_loss: 0.9113 - distillation_loss: 0.0079 - val_sparse_categorical_accuracy: 0.4570 - val_student_loss: 1.8657\n",
            "Epoch 68/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.7003 - student_loss: 0.9227 - distillation_loss: 0.0079 - val_sparse_categorical_accuracy: 0.4727 - val_student_loss: 1.7835\n",
            "Epoch 69/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6958 - student_loss: 0.9405 - distillation_loss: 0.0080 - val_sparse_categorical_accuracy: 0.4688 - val_student_loss: 1.7664\n",
            "Epoch 70/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.7037 - student_loss: 0.9086 - distillation_loss: 0.0080 - val_sparse_categorical_accuracy: 0.4883 - val_student_loss: 1.8163\n",
            "Epoch 71/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7064 - student_loss: 0.9129 - distillation_loss: 0.0080 - val_sparse_categorical_accuracy: 0.4688 - val_student_loss: 1.7640\n",
            "Epoch 72/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6975 - student_loss: 0.9260 - distillation_loss: 0.0080 - val_sparse_categorical_accuracy: 0.4805 - val_student_loss: 1.7594\n",
            "Epoch 73/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.7067 - student_loss: 0.9052 - distillation_loss: 0.0080 - val_sparse_categorical_accuracy: 0.4766 - val_student_loss: 1.8011\n",
            "Epoch 74/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6924 - student_loss: 0.9387 - distillation_loss: 0.0081 - val_sparse_categorical_accuracy: 0.4844 - val_student_loss: 1.7245\n",
            "Epoch 75/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.6968 - student_loss: 0.9278 - distillation_loss: 0.0080 - val_sparse_categorical_accuracy: 0.4805 - val_student_loss: 1.7728\n",
            "Epoch 76/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6991 - student_loss: 0.9188 - distillation_loss: 0.0079 - val_sparse_categorical_accuracy: 0.4766 - val_student_loss: 1.7511\n",
            "Epoch 77/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6991 - student_loss: 0.9310 - distillation_loss: 0.0081 - val_sparse_categorical_accuracy: 0.4609 - val_student_loss: 1.7816\n",
            "Epoch 78/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.6974 - student_loss: 0.9284 - distillation_loss: 0.0079 - val_sparse_categorical_accuracy: 0.5117 - val_student_loss: 1.7058\n",
            "Epoch 79/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7020 - student_loss: 0.9167 - distillation_loss: 0.0081 - val_sparse_categorical_accuracy: 0.5078 - val_student_loss: 1.7262\n",
            "Epoch 80/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.7041 - student_loss: 0.9139 - distillation_loss: 0.0080 - val_sparse_categorical_accuracy: 0.4727 - val_student_loss: 1.7903\n",
            "Epoch 81/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7050 - student_loss: 0.9140 - distillation_loss: 0.0081 - val_sparse_categorical_accuracy: 0.4648 - val_student_loss: 1.8160\n",
            "Epoch 82/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7074 - student_loss: 0.9080 - distillation_loss: 0.0080 - val_sparse_categorical_accuracy: 0.4688 - val_student_loss: 1.7918\n",
            "Epoch 83/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7030 - student_loss: 0.9026 - distillation_loss: 0.0081 - val_sparse_categorical_accuracy: 0.4766 - val_student_loss: 1.7931\n",
            "Epoch 84/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.7107 - student_loss: 0.9067 - distillation_loss: 0.0079 - val_sparse_categorical_accuracy: 0.4609 - val_student_loss: 1.8510\n",
            "Epoch 85/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7100 - student_loss: 0.9079 - distillation_loss: 0.0081 - val_sparse_categorical_accuracy: 0.4688 - val_student_loss: 1.8327\n",
            "Epoch 86/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.7077 - student_loss: 0.8985 - distillation_loss: 0.0081 - val_sparse_categorical_accuracy: 0.4609 - val_student_loss: 1.8667\n",
            "Epoch 87/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7098 - student_loss: 0.9083 - distillation_loss: 0.0081 - val_sparse_categorical_accuracy: 0.4609 - val_student_loss: 1.8943\n",
            "Epoch 88/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7021 - student_loss: 0.9024 - distillation_loss: 0.0081 - val_sparse_categorical_accuracy: 0.4648 - val_student_loss: 1.7952\n",
            "Epoch 89/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.7055 - student_loss: 0.9091 - distillation_loss: 0.0081 - val_sparse_categorical_accuracy: 0.4492 - val_student_loss: 1.8552\n",
            "Epoch 90/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7037 - student_loss: 0.9004 - distillation_loss: 0.0080 - val_sparse_categorical_accuracy: 0.4531 - val_student_loss: 1.8650\n",
            "Epoch 91/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.7077 - student_loss: 0.8977 - distillation_loss: 0.0080 - val_sparse_categorical_accuracy: 0.4531 - val_student_loss: 1.8660\n",
            "Epoch 92/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.7060 - student_loss: 0.8970 - distillation_loss: 0.0081 - val_sparse_categorical_accuracy: 0.4961 - val_student_loss: 1.7629\n",
            "Epoch 93/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7018 - student_loss: 0.9067 - distillation_loss: 0.0080 - val_sparse_categorical_accuracy: 0.5039 - val_student_loss: 1.7528\n",
            "Epoch 94/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.7061 - student_loss: 0.9141 - distillation_loss: 0.0082 - val_sparse_categorical_accuracy: 0.4922 - val_student_loss: 1.8088\n",
            "Epoch 95/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.7122 - student_loss: 0.8952 - distillation_loss: 0.0081 - val_sparse_categorical_accuracy: 0.4844 - val_student_loss: 1.7993\n",
            "Epoch 96/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7082 - student_loss: 0.9063 - distillation_loss: 0.0080 - val_sparse_categorical_accuracy: 0.4922 - val_student_loss: 1.7487\n",
            "Epoch 97/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7041 - student_loss: 0.9149 - distillation_loss: 0.0080 - val_sparse_categorical_accuracy: 0.4805 - val_student_loss: 1.7737\n",
            "Epoch 98/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.7098 - student_loss: 0.9005 - distillation_loss: 0.0081 - val_sparse_categorical_accuracy: 0.4766 - val_student_loss: 1.8329\n",
            "Epoch 99/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.7147 - student_loss: 0.8904 - distillation_loss: 0.0081 - val_sparse_categorical_accuracy: 0.4883 - val_student_loss: 1.7859\n",
            "Epoch 100/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.7070 - student_loss: 0.8998 - distillation_loss: 0.0081 - val_sparse_categorical_accuracy: 0.4961 - val_student_loss: 1.8175\n",
            "Epoch 101/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7109 - student_loss: 0.8928 - distillation_loss: 0.0082 - val_sparse_categorical_accuracy: 0.4492 - val_student_loss: 1.8945\n",
            "Epoch 102/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7089 - student_loss: 0.8978 - distillation_loss: 0.0080 - val_sparse_categorical_accuracy: 0.4492 - val_student_loss: 1.9100\n",
            "Epoch 103/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7127 - student_loss: 0.8907 - distillation_loss: 0.0081 - val_sparse_categorical_accuracy: 0.4688 - val_student_loss: 1.8338\n",
            "Epoch 104/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7164 - student_loss: 0.8843 - distillation_loss: 0.0082 - val_sparse_categorical_accuracy: 0.4648 - val_student_loss: 1.8074\n",
            "Epoch 105/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7091 - student_loss: 0.8986 - distillation_loss: 0.0081 - val_sparse_categorical_accuracy: 0.4648 - val_student_loss: 1.8628\n",
            "Epoch 106/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7120 - student_loss: 0.8786 - distillation_loss: 0.0081 - val_sparse_categorical_accuracy: 0.4727 - val_student_loss: 1.8747\n",
            "Epoch 107/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.7099 - student_loss: 0.8736 - distillation_loss: 0.0082 - val_sparse_categorical_accuracy: 0.4688 - val_student_loss: 1.8795\n",
            "Epoch 108/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.7203 - student_loss: 0.8607 - distillation_loss: 0.0081 - val_sparse_categorical_accuracy: 0.4922 - val_student_loss: 1.8092\n",
            "Epoch 109/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7098 - student_loss: 0.8866 - distillation_loss: 0.0082 - val_sparse_categorical_accuracy: 0.4766 - val_student_loss: 1.8424\n",
            "Epoch 110/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7122 - student_loss: 0.8791 - distillation_loss: 0.0081 - val_sparse_categorical_accuracy: 0.4805 - val_student_loss: 1.8186\n",
            "Epoch 111/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.7133 - student_loss: 0.8935 - distillation_loss: 0.0082 - val_sparse_categorical_accuracy: 0.4609 - val_student_loss: 1.9116\n",
            "Epoch 112/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.7156 - student_loss: 0.8767 - distillation_loss: 0.0080 - val_sparse_categorical_accuracy: 0.4570 - val_student_loss: 1.9379\n",
            "Epoch 113/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7174 - student_loss: 0.8719 - distillation_loss: 0.0081 - val_sparse_categorical_accuracy: 0.4727 - val_student_loss: 1.8618\n",
            "Epoch 114/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7211 - student_loss: 0.8594 - distillation_loss: 0.0082 - val_sparse_categorical_accuracy: 0.4609 - val_student_loss: 1.8243\n",
            "Epoch 115/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7107 - student_loss: 0.8878 - distillation_loss: 0.0081 - val_sparse_categorical_accuracy: 0.4727 - val_student_loss: 1.8006\n",
            "Epoch 116/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.7182 - student_loss: 0.8721 - distillation_loss: 0.0082 - val_sparse_categorical_accuracy: 0.4766 - val_student_loss: 1.7997\n",
            "Epoch 117/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.7137 - student_loss: 0.8911 - distillation_loss: 0.0082 - val_sparse_categorical_accuracy: 0.4883 - val_student_loss: 1.6983\n",
            "Epoch 118/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7156 - student_loss: 0.8764 - distillation_loss: 0.0082 - val_sparse_categorical_accuracy: 0.4570 - val_student_loss: 1.7921\n",
            "Epoch 119/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.7163 - student_loss: 0.8696 - distillation_loss: 0.0082 - val_sparse_categorical_accuracy: 0.4961 - val_student_loss: 1.8088\n",
            "Epoch 120/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7190 - student_loss: 0.8797 - distillation_loss: 0.0082 - val_sparse_categorical_accuracy: 0.4648 - val_student_loss: 1.8274\n",
            "Epoch 121/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7137 - student_loss: 0.8860 - distillation_loss: 0.0081 - val_sparse_categorical_accuracy: 0.4805 - val_student_loss: 1.8072\n",
            "Epoch 122/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7107 - student_loss: 0.8819 - distillation_loss: 0.0082 - val_sparse_categorical_accuracy: 0.4844 - val_student_loss: 1.8523\n",
            "Epoch 123/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7112 - student_loss: 0.8815 - distillation_loss: 0.0082 - val_sparse_categorical_accuracy: 0.4844 - val_student_loss: 1.8231\n",
            "Epoch 124/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.7128 - student_loss: 0.8805 - distillation_loss: 0.0082 - val_sparse_categorical_accuracy: 0.4883 - val_student_loss: 1.8128\n",
            "Epoch 125/180\n",
            "20/20 [==============================] - 1s 43ms/step - sparse_categorical_accuracy: 0.7242 - student_loss: 0.8664 - distillation_loss: 0.0082 - val_sparse_categorical_accuracy: 0.4609 - val_student_loss: 1.8479\n",
            "Epoch 126/180\n",
            "20/20 [==============================] - 1s 43ms/step - sparse_categorical_accuracy: 0.7168 - student_loss: 0.8675 - distillation_loss: 0.0083 - val_sparse_categorical_accuracy: 0.4688 - val_student_loss: 1.8650\n",
            "Epoch 127/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7205 - student_loss: 0.8652 - distillation_loss: 0.0082 - val_sparse_categorical_accuracy: 0.4648 - val_student_loss: 1.9330\n",
            "Epoch 128/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7195 - student_loss: 0.8608 - distillation_loss: 0.0082 - val_sparse_categorical_accuracy: 0.4570 - val_student_loss: 1.8881\n",
            "Epoch 129/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7224 - student_loss: 0.8656 - distillation_loss: 0.0082 - val_sparse_categorical_accuracy: 0.4609 - val_student_loss: 1.9025\n",
            "Epoch 130/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7167 - student_loss: 0.8761 - distillation_loss: 0.0081 - val_sparse_categorical_accuracy: 0.4766 - val_student_loss: 1.8707\n",
            "Epoch 131/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7271 - student_loss: 0.8460 - distillation_loss: 0.0082 - val_sparse_categorical_accuracy: 0.4570 - val_student_loss: 1.8391\n",
            "Epoch 132/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7241 - student_loss: 0.8547 - distillation_loss: 0.0083 - val_sparse_categorical_accuracy: 0.4688 - val_student_loss: 1.7685\n",
            "Epoch 133/180\n",
            "20/20 [==============================] - 1s 43ms/step - sparse_categorical_accuracy: 0.7226 - student_loss: 0.8398 - distillation_loss: 0.0082 - val_sparse_categorical_accuracy: 0.4609 - val_student_loss: 1.7888\n",
            "Epoch 134/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7229 - student_loss: 0.8615 - distillation_loss: 0.0082 - val_sparse_categorical_accuracy: 0.4727 - val_student_loss: 1.8001\n",
            "Epoch 135/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.7208 - student_loss: 0.8525 - distillation_loss: 0.0082 - val_sparse_categorical_accuracy: 0.4688 - val_student_loss: 1.7441\n",
            "Epoch 136/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7312 - student_loss: 0.8447 - distillation_loss: 0.0082 - val_sparse_categorical_accuracy: 0.4727 - val_student_loss: 1.7748\n",
            "Epoch 137/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7224 - student_loss: 0.8582 - distillation_loss: 0.0083 - val_sparse_categorical_accuracy: 0.4609 - val_student_loss: 1.8395\n",
            "Epoch 138/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7161 - student_loss: 0.8730 - distillation_loss: 0.0082 - val_sparse_categorical_accuracy: 0.4492 - val_student_loss: 1.8607\n",
            "Epoch 139/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7241 - student_loss: 0.8480 - distillation_loss: 0.0083 - val_sparse_categorical_accuracy: 0.4688 - val_student_loss: 1.8144\n",
            "Epoch 140/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7190 - student_loss: 0.8661 - distillation_loss: 0.0083 - val_sparse_categorical_accuracy: 0.4648 - val_student_loss: 1.8598\n",
            "Epoch 141/180\n",
            "20/20 [==============================] - 1s 43ms/step - sparse_categorical_accuracy: 0.7249 - student_loss: 0.8479 - distillation_loss: 0.0084 - val_sparse_categorical_accuracy: 0.4688 - val_student_loss: 1.8386\n",
            "Epoch 142/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7310 - student_loss: 0.8499 - distillation_loss: 0.0082 - val_sparse_categorical_accuracy: 0.4609 - val_student_loss: 1.8100\n",
            "Epoch 143/180\n",
            "20/20 [==============================] - 1s 41ms/step - sparse_categorical_accuracy: 0.7250 - student_loss: 0.8450 - distillation_loss: 0.0082 - val_sparse_categorical_accuracy: 0.4570 - val_student_loss: 1.7893\n",
            "Epoch 144/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7234 - student_loss: 0.8618 - distillation_loss: 0.0083 - val_sparse_categorical_accuracy: 0.4688 - val_student_loss: 1.7893\n",
            "Epoch 145/180\n",
            "20/20 [==============================] - 1s 43ms/step - sparse_categorical_accuracy: 0.7251 - student_loss: 0.8481 - distillation_loss: 0.0083 - val_sparse_categorical_accuracy: 0.4766 - val_student_loss: 1.8531\n",
            "Epoch 146/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7271 - student_loss: 0.8420 - distillation_loss: 0.0082 - val_sparse_categorical_accuracy: 0.4531 - val_student_loss: 1.8573\n",
            "Epoch 147/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7270 - student_loss: 0.8354 - distillation_loss: 0.0083 - val_sparse_categorical_accuracy: 0.4414 - val_student_loss: 1.9720\n",
            "Epoch 148/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7235 - student_loss: 0.8459 - distillation_loss: 0.0083 - val_sparse_categorical_accuracy: 0.4727 - val_student_loss: 1.8557\n",
            "Epoch 149/180\n",
            "20/20 [==============================] - 1s 43ms/step - sparse_categorical_accuracy: 0.7197 - student_loss: 0.8660 - distillation_loss: 0.0083 - val_sparse_categorical_accuracy: 0.4805 - val_student_loss: 1.8543\n",
            "Epoch 150/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7272 - student_loss: 0.8522 - distillation_loss: 0.0083 - val_sparse_categorical_accuracy: 0.4883 - val_student_loss: 1.8338\n",
            "Epoch 151/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7244 - student_loss: 0.8581 - distillation_loss: 0.0083 - val_sparse_categorical_accuracy: 0.4531 - val_student_loss: 1.8857\n",
            "Epoch 152/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7230 - student_loss: 0.8507 - distillation_loss: 0.0082 - val_sparse_categorical_accuracy: 0.4805 - val_student_loss: 1.8354\n",
            "Epoch 153/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7186 - student_loss: 0.8565 - distillation_loss: 0.0083 - val_sparse_categorical_accuracy: 0.4688 - val_student_loss: 1.8694\n",
            "Epoch 154/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7264 - student_loss: 0.8502 - distillation_loss: 0.0083 - val_sparse_categorical_accuracy: 0.4688 - val_student_loss: 1.8673\n",
            "Epoch 155/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7265 - student_loss: 0.8396 - distillation_loss: 0.0083 - val_sparse_categorical_accuracy: 0.4648 - val_student_loss: 1.8564\n",
            "Epoch 156/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7231 - student_loss: 0.8378 - distillation_loss: 0.0083 - val_sparse_categorical_accuracy: 0.4727 - val_student_loss: 1.8885\n",
            "Epoch 157/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7262 - student_loss: 0.8409 - distillation_loss: 0.0082 - val_sparse_categorical_accuracy: 0.4805 - val_student_loss: 1.8746\n",
            "Epoch 158/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7217 - student_loss: 0.8492 - distillation_loss: 0.0083 - val_sparse_categorical_accuracy: 0.4922 - val_student_loss: 1.8633\n",
            "Epoch 159/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7292 - student_loss: 0.8402 - distillation_loss: 0.0083 - val_sparse_categorical_accuracy: 0.4609 - val_student_loss: 1.8157\n",
            "Epoch 160/180\n",
            "20/20 [==============================] - 1s 43ms/step - sparse_categorical_accuracy: 0.7342 - student_loss: 0.8305 - distillation_loss: 0.0083 - val_sparse_categorical_accuracy: 0.4805 - val_student_loss: 1.8071\n",
            "Epoch 161/180\n",
            "20/20 [==============================] - 1s 43ms/step - sparse_categorical_accuracy: 0.7231 - student_loss: 0.8455 - distillation_loss: 0.0084 - val_sparse_categorical_accuracy: 0.4805 - val_student_loss: 1.8337\n",
            "Epoch 162/180\n",
            "20/20 [==============================] - 1s 43ms/step - sparse_categorical_accuracy: 0.7332 - student_loss: 0.8207 - distillation_loss: 0.0083 - val_sparse_categorical_accuracy: 0.4766 - val_student_loss: 1.8209\n",
            "Epoch 163/180\n",
            "20/20 [==============================] - 1s 43ms/step - sparse_categorical_accuracy: 0.7206 - student_loss: 0.8648 - distillation_loss: 0.0084 - val_sparse_categorical_accuracy: 0.4570 - val_student_loss: 1.8288\n",
            "Epoch 164/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7286 - student_loss: 0.8344 - distillation_loss: 0.0083 - val_sparse_categorical_accuracy: 0.4727 - val_student_loss: 1.8287\n",
            "Epoch 165/180\n",
            "20/20 [==============================] - 1s 43ms/step - sparse_categorical_accuracy: 0.7270 - student_loss: 0.8348 - distillation_loss: 0.0083 - val_sparse_categorical_accuracy: 0.4727 - val_student_loss: 1.8823\n",
            "Epoch 166/180\n",
            "20/20 [==============================] - 1s 43ms/step - sparse_categorical_accuracy: 0.7272 - student_loss: 0.8400 - distillation_loss: 0.0082 - val_sparse_categorical_accuracy: 0.4688 - val_student_loss: 1.9001\n",
            "Epoch 167/180\n",
            "20/20 [==============================] - 1s 43ms/step - sparse_categorical_accuracy: 0.7274 - student_loss: 0.8354 - distillation_loss: 0.0083 - val_sparse_categorical_accuracy: 0.4609 - val_student_loss: 1.9126\n",
            "Epoch 168/180\n",
            "20/20 [==============================] - 1s 43ms/step - sparse_categorical_accuracy: 0.7296 - student_loss: 0.8268 - distillation_loss: 0.0084 - val_sparse_categorical_accuracy: 0.4648 - val_student_loss: 1.8923\n",
            "Epoch 169/180\n",
            "20/20 [==============================] - 1s 43ms/step - sparse_categorical_accuracy: 0.7333 - student_loss: 0.8390 - distillation_loss: 0.0084 - val_sparse_categorical_accuracy: 0.4531 - val_student_loss: 1.9225\n",
            "Epoch 170/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7280 - student_loss: 0.8282 - distillation_loss: 0.0083 - val_sparse_categorical_accuracy: 0.4375 - val_student_loss: 1.9469\n",
            "Epoch 171/180\n",
            "20/20 [==============================] - 1s 43ms/step - sparse_categorical_accuracy: 0.7281 - student_loss: 0.8323 - distillation_loss: 0.0084 - val_sparse_categorical_accuracy: 0.4258 - val_student_loss: 2.0025\n",
            "Epoch 172/180\n",
            "20/20 [==============================] - 1s 43ms/step - sparse_categorical_accuracy: 0.7322 - student_loss: 0.8438 - distillation_loss: 0.0084 - val_sparse_categorical_accuracy: 0.4648 - val_student_loss: 1.9876\n",
            "Epoch 173/180\n",
            "20/20 [==============================] - 1s 46ms/step - sparse_categorical_accuracy: 0.7293 - student_loss: 0.8396 - distillation_loss: 0.0084 - val_sparse_categorical_accuracy: 0.4609 - val_student_loss: 1.9129\n",
            "Epoch 174/180\n",
            "20/20 [==============================] - 1s 45ms/step - sparse_categorical_accuracy: 0.7249 - student_loss: 0.8352 - distillation_loss: 0.0084 - val_sparse_categorical_accuracy: 0.4727 - val_student_loss: 1.8611\n",
            "Epoch 175/180\n",
            "20/20 [==============================] - 1s 45ms/step - sparse_categorical_accuracy: 0.7227 - student_loss: 0.8377 - distillation_loss: 0.0084 - val_sparse_categorical_accuracy: 0.4688 - val_student_loss: 1.8069\n",
            "Epoch 176/180\n",
            "20/20 [==============================] - 1s 46ms/step - sparse_categorical_accuracy: 0.7246 - student_loss: 0.8399 - distillation_loss: 0.0084 - val_sparse_categorical_accuracy: 0.4727 - val_student_loss: 1.8149\n",
            "Epoch 177/180\n",
            "20/20 [==============================] - 1s 44ms/step - sparse_categorical_accuracy: 0.7291 - student_loss: 0.8377 - distillation_loss: 0.0084 - val_sparse_categorical_accuracy: 0.4648 - val_student_loss: 1.8341\n",
            "Epoch 178/180\n",
            "20/20 [==============================] - 1s 42ms/step - sparse_categorical_accuracy: 0.7237 - student_loss: 0.8378 - distillation_loss: 0.0083 - val_sparse_categorical_accuracy: 0.4688 - val_student_loss: 1.8635\n",
            "Epoch 179/180\n",
            "20/20 [==============================] - 1s 43ms/step - sparse_categorical_accuracy: 0.7312 - student_loss: 0.8255 - distillation_loss: 0.0083 - val_sparse_categorical_accuracy: 0.4609 - val_student_loss: 1.8793\n",
            "Epoch 180/180\n",
            "20/20 [==============================] - 1s 43ms/step - sparse_categorical_accuracy: 0.7267 - student_loss: 0.8436 - distillation_loss: 0.0084 - val_sparse_categorical_accuracy: 0.4570 - val_student_loss: 1.8717\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f37121c3100>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "# Initialize and compile distiller\n",
        "distiller = Distiller(student=student, teacher=teacher)\n",
        "distiller.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        "    student_loss_fn=keras.losses.SparseCategoricalCrossentropy(),\n",
        "    distillation_loss_fn=keras.losses.KLDivergence(),\n",
        "    alpha=0.1,\n",
        "    temperature=10,\n",
        "    #run_eagerly=True\n",
        ")\n",
        "\n",
        "# Distill teacher to student\n",
        "print('train steps: ', train_steps)\n",
        "distiller.fit(train_data.repeat(), steps_per_epoch=train_steps, validation_data=val_data.repeat(),validation_steps=val_steps, epochs=180)\n",
        "#distiller.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "# Evaluate student on test dataset\n",
        "#distiller.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save model\n",
        "# print(\"Saving model\")\n",
        "#distiller.save(\"../models/student_128\", save_format='tf')\n",
        "#distiller.save_weights(\"../models/student_128_weights.h5\")\n",
        "\n",
        "student.save(\"../models/student_2560_60ep_conv2dis2.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ufmn8Dd7Uuty",
        "outputId": "ae9fdeb9-16fe-42e6-fe39-417746ac7cce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf. __version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqg1Us8LVfYo",
        "outputId": "73e3ea42-af9d-4418-9f3a-3af089cf0585"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test if the model will load properly\n",
        "studLoaded = load_model(\"../models/student_2560_60ep_conv2dis2.h5\")\n",
        "student_scratch.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "for x, y in val_data:\n",
        "  pred = student.predict(x)\n",
        "  print(pred)\n",
        "  break"
      ],
      "metadata": {
        "id": "-b2RvkI4KsMC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6d948aa-6473-4905-9866-0774d9948162"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 3ms/step\n",
            "[[1.06369100e-08 8.56202576e-09 3.49572343e-10 ... 3.30489214e-09\n",
            "  2.19917656e-05 4.40445288e-13]\n",
            " [2.05039237e-06 4.40136070e-08 1.12538434e-09 ... 1.79116881e-07\n",
            "  8.49887147e-05 7.46302380e-13]\n",
            " [1.00848325e-07 3.64679025e-08 7.26648874e-09 ... 1.42121246e-06\n",
            "  1.16497839e-10 3.99900680e-13]\n",
            " ...\n",
            " [8.98901042e-09 1.08532805e-09 9.16671392e-11 ... 2.43806610e-08\n",
            "  1.00140223e-10 3.88278548e-15]\n",
            " [5.84910813e-05 2.09029793e-04 5.76701888e-04 ... 3.24938089e-01\n",
            "  3.41269970e-06 1.15929510e-09]\n",
            " [4.67523278e-05 1.86387841e-02 1.00867464e-05 ... 1.60899472e-05\n",
            "  8.50854576e-07 3.89951405e-09]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5BavmmX2Xbe"
      },
      "source": [
        "## Train student from scratch for comparison\n",
        "\n",
        "We can also train an equivalent student model from scratch without the teacher, in order\n",
        "to evaluate the performance gain obtained by knowledge distillation."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "load the baseline model\n",
        "\n",
        "for CONV2D param:\n",
        "  record the size of the model\n",
        "  for num_data:\n",
        "    distill the model\n",
        "    on validation set, record sparse_val_accuracy, pr/recall on Marvin, and training time\n",
        "    save the model\n",
        "    save the stats\n",
        "```\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "TibZmBma2EBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_teacher(path_to_teacher):\n",
        "  teacher = load_model(path_to_teacher) #julian model: models/marvin_kws_Dec1_5pm.h5\n",
        "  teacher.summary()\n",
        "  return teacher\n",
        "\n",
        "\n",
        "def create_student(conv2dparam):\n",
        "  \"\"\"\n",
        "  conv2dparam: a list of 5, each divisible by 2, specifying params in CONV2D filter layers\n",
        "  returns: a student model and its clone, where student model is distilled to and clone trained from scratch\n",
        "  \"\"\"\n",
        "  student = create_model(conv2dparam)\n",
        "  student_scratch = keras.models.clone_model(student)\n",
        "  return student, student_scratch\n"
      ],
      "metadata": {
        "id": "cYtreIX13LrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_distilled_models = \"\"\n",
        "path_to_scratch_models = \"\"\n",
        "distilled_models_name = \"distilled_model_param_{}_data_samples_{}\"\n",
        "scratch_models_name = \"scratch_model_param_{}_data_samples_{}\"\n",
        "path_to_distilled_stats = \"\"\n",
        "path_to_scratch_stats = \"\"\n",
        "\n",
        "def train_loop(conv2dls, data_samples):\n",
        "\n",
        "  teacher = load_teacher(path_to_teacher)\n",
        "\n",
        "  for conv2d in conv2dls:\n",
        "    for data_length in data_samples:\n",
        "      train_data, train_steps, val_data, val_steps = create_tf_dataset(data_length)\n",
        "      \n",
        "      student, student_scratch = create_student(conv2d)\n",
        "      distiller = Distiller(student=student, teacher=teacher)\n",
        "      distiller.compile(\n",
        "          optimizer=keras.optimizers.Adam(),\n",
        "          metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        "          student_loss_fn=keras.losses.SparseCategoricalCrossentropy(),\n",
        "          distillation_loss_fn=keras.losses.KLDivergence(),\n",
        "          alpha=0.1,\n",
        "          temperature=10,\n",
        "          #run_eagerly=True\n",
        "      )\n",
        "\n",
        "      distiller.fit(train_data.repeat(), steps_per_epoch=train_steps, validation_data=val_data.repeat(),validation_steps=val_steps, epochs=30)\n",
        "      #save student, save stats\n",
        "      student.save(path_to_distilled_models + distilled_models_name.format(conv2d, data_length))\n",
        "\n",
        "      #train scratch, save stats\n",
        "      student_scratch.fit(train_data.repeat(), steps_per_epoch=train_steps, validation_data=val_data.repeat(),validation_steps=val_steps, epochs=30)\n",
        "      student_scratch.save(path_to_scratch_models + scratch_models_name.format(conv2d, data_length))\n",
        "\n",
        "ogconv2d = [8, 16, 32, 64, 128]\n",
        "conv2dls = [ogconv2d, [elt//2 for elt in ogconv2d], [elt//4 for elt in ogconv2d]][::-1]\n",
        "ds = None #50,000?\n",
        "data_samples = [ds, ds//2, ds//4, ds//20][::-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "ZGAz30LN4eAS",
        "outputId": "6efc4b4d-4f9b-4b6b-a476-e089f417de68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-59d5ba9a3ee3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mconv2dls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mogconv2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0melt\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mogconv2d\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0melt\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mogconv2d\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mdata_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for //: 'NoneType' and 'int'"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}